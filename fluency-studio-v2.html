<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>MedAI Fluency Studio</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/canvas-confetti@1.6.0/dist/confetti.browser.min.js"></script>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;600;700&family=Playfair+Display:wght@700&display=swap" rel="stylesheet">
  <style>
    html { scroll-behavior: smooth; }
    body { font-family: 'Roboto', sans-serif; background-color: #f8fafc; color: #1e293b; }
    h1, h2 { font-family: 'Playfair Display', serif; font-weight: 700; }
    .question-text { font-weight: 600; }
    .answer-text { font-weight: 400; }
    .option { @apply flex items-center gap-4 p-3 rounded-lg cursor-pointer hover:bg-indigo-50 transition; }
    .option input { @apply w-5 h-5 text-indigo-600; }
  </style>
</head>
<body class="min-h-screen py-12">
<!-- Top-right "Back to Lexicon" link -->
  <div class="fixed top-4 right-6 z-50">
    <a href="index.html" class="inline-flex items-center gap-2 bg-white/90 backdrop-blur-sm px-5 py-3 rounded-full shadow-lg border border-slate-200 text-slate-700 font-medium hover:bg-indigo-50 hover:text-indigo-700 transition">
      <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 19l-7-7m0 0l7-7m-7 7h18"/></svg>
      Back to MedAI Lexicon
    </a>
  </div>
  
  <div class="max-w-4xl mx-auto px-6">
    <header class="text-center mb-16">
      <h1 class="text-3xl md:text-4xl font-bold text-slate-900 mb-4">MedAI Fluency </h1>
      <p class="text-lg text-slate-600">Answer the quiz questions, then view your MedAI fluency map and learning path at the bottom of the page.</p>
    </header>

    <form id="quiz" class="space-y-10 mb-24"></form>

    <section id="results" class="hidden">
      <div class="bg-white rounded-3xl shadow-2xl p-10 md:p-14 text-center">
        <h2 class="text-3xl md:text-4xl font-bold text-slate-900 mb-10">Your MedAI Fluency Profile</h2>
        <div class="max-w-md mx-auto">
          <canvas id="radar"></canvas>
        </div>
        <p class="text-5xl font-bold text-indigo-700 mt-10" id="score"></p>
        <p class="text-xl text-slate-700 mt-4" id="message"></p>
        <div id="focus-areas" class="mt-10 text-base text-slate-700"></div>
        <div class="mt-12 flex flex-col sm:flex-row gap-6 justify-center">
          <a href="micromodules.html" class="px-10 py-5 bg-indigo-600 text-white font-semibold text-base rounded-full hover:bg-indigo-700 transition shadow-lg">
            Watch Recommended Videos
          </a>
          <button onclick="location.reload()" class="px-10 py-5 bg-white border-2 border-indigo-600 text-indigo-700 font-semibold text-base rounded-full hover:bg-indigo-50 transition">
            Take Quiz Again
          </button>
        </div>
        <details class="mt-12 max-w-3xl mx-auto text-left">
          <summary class="text-xl font-semibold text-slate-700 cursor-pointer hover:text-indigo-700 py-4">
            Show questions I got wrong
          </summary>
          <div id="review" class="mt-6 space-y-6"></div>
        </details>
      </div>
    </section>
  </div>

  <script>
    const questionBank = [
      // CLUSTER 1: Prompt Mastery & Conversation Patterns (20 questions)
      {q:"Chain-of-thought prompting improves reasoning by:", a:"Letting the model generate intermediate steps", d:["Making the model think faster","Reducing the number of tokens used","Automatically adding safety filters"], e:"CoT gives the model space to reason step-by-step (Module 09).", c:1},
      {q:"Higher temperature setting produces:", a:"More creative / diverse output", d:["More accurate medical advice","Shorter responses","Lower cost per token"], e:"Use low temperature for reliable clinical answers (Module 01).", c:1},
      {q:"Few-shot prompting means:", a:"Including examples in the prompt", d:["Using zero examples","Fine-tuning the model","Adding images to the prompt"], e:"Few-shot guides the model without retraining (Module 01).", c:1},
      {q:"The system prompt is used to:", a:"Define the AI's role and behavior rules", d:["Set the output length only","Define the token limit","Set the temperature value"], e:"System prompt sets personality and safety rules (Module 01).", c:1},
      {q:"Style transfer in prompts refers to:", a:"Making output match a specific tone or format", d:["Changing the model architecture","Transferring data between models","Styling the user interface"], e:"Used for patient education in simple language (Module 01).", c:1},
      {q:"Zero-shot prompting means:", a:"No examples given", d:["One example given","Multiple examples given","Fine-tuning required"], e:"Relies only on pre-training (Module 01).", c:1},
      {q:"Best practice for medical prompts is to:", a:"Be specific, provide context, ask for reasoning", d:["Keep it vague to encourage creativity","Use high temperature for accuracy","Avoid mentioning the patient's condition"], e:"Clear prompts lead to safer answers (Module 01).", c:1},
      {q:"Why do models sometimes refuse tasks?", a:"Because of safety filters in post-training", d:["They are out of tokens","The prompt is too long","The temperature is too low"], e:"Safety filters from RLHF (Module 14).", c:1},
      {q:"Temperature = 0 means:", a:"Fully deterministic output", d:["Maximum creativity","Random sampling","Error mode"], e:"Always the most likely token (Module 01).", c:1},
      {q:"Sampling methods like top-p affect:", a:"How creative the output is", d:["Token count only","Model size","Training time"], e:"Controls diversity of responses (Module 01).", c:1},
      {q:"For clinical questions you want:", a:"Low temperature so answers are stable", d:["High temperature for brainstorming","No temperature setting","Random sampling"], e:"Reproducible answers are safer (Module 01).", c:1},
      {q:"CoT is especially useful for:", a:"Complex reasoning or long chain explanations", d:["Simple fact lookup","Image generation","Code execution"], e:"Step-by-step differentials reduce errors (Module 09).", c:1},
      {q:"System prompt is most important for:", a:"Consistent behavior across conversations", d:["Speeding up inference","Reducing hallucinations","Adding more context tokens"], e:"Sets the rules for the entire session (Module 01).", c:1},
      {q:"Few-shot is better than zero-shot when:", a:"You can provide relevant examples", d:["The prompt is very short","Temperature is high","Model is small"], e:"Examples guide the model (Module 01).", c:1},
      {q:"Prompt engineering is like:", a:"Writing a focused question for radiology", d:["Building a model from scratch","Training on new data","Fine-tuning LoRA adapters"], e:"Clear consult request = clear answer (Module 01).", c:1},
      {q:"The best prompts include:", a:"Brief clinical history, key concern, what you want clarified", d:["Just 'please comment'","Vague questions","High token count only"], e:"Structure leads to better output (Module 01).", c:1},
      {q:"Top-k sampling chooses from:", a:"The top k most likely tokens", d:["All tokens equally","Random tokens","Only safe tokens"], e:"Controls diversity (Module 01).", c:1},
      {q:"Nucleus sampling (top-p) is better than top-k because:", a:"It adapts to the probability distribution", d:["It uses fewer tokens","It is faster","It reduces cost"], e:"Dynamic selection (Module 01).", c:1},
      {q:"In medical prompts, always include:", a:"What decision depends on the answer", d:["Only the symptom list","High temperature","No reasoning request"], e:"Helps the model understand importance (Module 01).", c:1},
      {q:"For brainstorming patient education phrases, use:", a:"Slightly higher temperature", d:["Temperature 0","Zero-shot only","No prompt"], e:"Allows varied wording (Module 01).", c:1},

      // CLUSTER 2: Model Fundamentals & Limitations (20 questions)
      {q:"Tokenization is:", a:"Breaking text into small pieces the model can process", d:["Compressing images","Encrypting data","Translating languages"], e:"Like cutting a discharge summary into beads (Module 02).", c:2},
      {q:"Embeddings are:", a:"Numerical coordinates that place words in a meaning space", d:["The raw text input","The final output","Safety filters"], e:"Similar things sit close together (Module 02).", c:2},
      {q:"Latent space is:", a:"The internal concept space where the model organizes meanings", d:["Token storage","Training data","Output layer"], e:"Like a galaxy map of concepts (Module 02).", c:2},
      {q:"Hallucinations are:", a:"Confident but incorrect or fabricated outputs", d:["Correct answers","Refusals to answer","Slow responses"], e:"Like a trainee inventing a journal article (Module 07).", c:2},
      {q:"Positional encoding tells the model:", a:"The order of tokens in a sequence", d:["The meaning of tokens","The safety rules","The temperature"], e:"Like numbering beads on a string (Module 02).", c:2},
      {q:"Attention heads are:", a:"Parallel pattern detectors that focus on different relationships", d:["Single detectors","Image processors","Safety filters"], e:"Like multiple specialists at a case conference (Module 03).", c:2},
      {q:"Residual streams are:", a:"Connections that carry information forward without erasing it", d:["Speed optimizers","Token counters","Safety layers"], e:"Like a river passing through locks (Module 03).", c:2},
      {q:"Scaling laws describe:", a:"How performance improves with more data, parameters, and compute", d:["How models get smaller","How cost decreases","How speed increases"], e:"Like growth charts for models (Module 10).", c:2},
      {q:"Training vs inference:", a:"Training = learning, inference = using", d:["Both the same","Training is faster","Inference requires data"], e:"Training is school, inference is practice (Module 04).", c:2},
      {q:"Emergent abilities are:", a:"New skills that appear when models become large enough", d:["Skills present in small models","Planned features","Safety features"], e:"Like a trainee suddenly managing complex patients (Module 13).", c:2},
      {q:"The model has no real understanding, only:", a:"Pattern completion from training data", d:["Real consciousness","Medical knowledge","Self-awareness"], e:"It's a probabilistic next-token generator (Module 07).", c:2},
      {q:"Why do LLMs struggle with letter counting?", a:"Because of tokenization", d:["Because they are small","Because of high temperature","Because of safety filters"], e:"Tokens don't match letters (Module 02).", c:2},
      {q:"Attention heads specialize in:", a:"Different patterns like syntax or long-range dependencies", d:["Only medical terms","Only images","Only safety"], e:"Some track pronouns, others negations (Module 03).", c:2},
      {q:"Residual streams allow:", a:"Later layers to still access original input", d:["Faster inference","Smaller model size","More creativity"], e:"Successive consults keep the initial history (Module 03).", c:2},
      {q:"Jagged performance refers to:", a:"Strong in some areas, weak in others", d:["Uniform performance","Always perfect","No performance"], e:"Miscounts labs but writes well (Module 11).", c:2},
      {q:"The model 'compresses' knowledge into:", a:"Latent space representations", d:["Raw text","Training data","Output tokens"], e:"Like clinical intuition (Module 03).", c:2},
      {q:"Why can't LLMs reliably spell backwards?", a:"Tokenization breaks words into pieces", d:["They are not trained","Temperature too high","Safety filters"], e:"Common tokenization flaw (Module 11).", c:2},
      {q:"Training data for most LLMs comes from:", a:"The public.de internet", d:["Only medical textbooks","Only PubMed","Only clinical notes"], e:"Common Crawl, FineWeb, etc. (Module 01).", c:2},
      {q:"The model has no memory of past conversations unless:", a:"You include it in the prompt", d:["It learns in real time","It has infinite context","It is fine-tuned"], e:"Context window limitation (Module 04).", c:2},
      {q:"Emergent abilities include:", a:"Translation, code generation, complex reasoning", d:["Only medical tasks","Only simple tasks","No new abilities"], e:"Appear at scale (Module 13).", c:2},

      // CLUSTER 3: Practical Use Cases (20 questions)
      {q:"RAG is:", a:"Retrieval-Augmented Generation", d:["Random Access Generation","Real-time AI Generation","Recursive Answer Generation"], e:"Pulls current guidelines to reduce hallucinations (Module 15).", c:3},
      {q:"AI agents can:", a:"Plan, call tools, review results, and iterate", d:["Only answer questions","Never make mistakes","Run without internet"], e:"Like a junior colleague (Module 15).", c:3},
      {q:"Quantization allows:", a:"Running large models on laptops", d:["Training from scratch","Increasing model size","Adding more data"], e:"8-bit or 4-bit versions (Module 05).", c:3},
      {q:"LoRA is:", a:"Low-rank adaptation for efficient fine-tuning", d:["A new model architecture","A safety filter","A data center"], e:"Add-on matrices, not full training (Module 05).", c:3},
      {q:"Diffusion models are used for:", a:"Image generation", d:["Text generation","Tokenization","Safety alignment"], e:"From noise to clear images (Module 15).", c:3},
      {q:"Multimodal fusion means:", a:"Models that process text, images, and audio together", d:["Text only","Images only","Audio only"], e:"Like a clinician integrating data (Module 15).", c:3},
      {q:"AI data centers are needed because:", a:"Training and inference require massive GPU clusters", d:["Models run on phones","Training is cheap","No compute needed"], e:"Giant hospitals for computation (Module 15).", c:3},
      {q:"RAG helps with:", a:"Keeping answers current and reducing hallucinations", d:["Increasing creativity","Reducing cost","Speeding up training"], e:"Pulls latest guidelines (Module 15).", c:3},
      {q:"Quantized models make possible:", a:"On-device AI tools in clinic", d:["Training larger models","Adding more data","Increasing temperature"], e:"Run on tablet without cloud (Module 05).", c:3},
      {q:"LoRA adapters can specialize in:", a:"Oncology, cardiology, etc.", d:["Only general medicine","Only research","Only education"], e:"Single base model + different adapters (Module 05).", c:3},
      {q:"Diffusion models in medicine can:", a:"Generate educational images or simulate rare findings", d:["Diagnose patients","Replace radiologists","Write notes"], e:"Must be clearly labeled (Module 15).", c:3},
      {q:"Multimodal models could:", a:"Consider CT images, vitals, and notes at once", d:["Only read notes","Only view images","Only listen to audio"], e:"Richer phenotyping (Module 15).", c:3},
      {q:"AI agents could:", a:"Gather imaging, summarize notes, draft orders", d:["Only answer questions","Never revise","Work alone"], e:"With human supervision (Module 15).", c:3},
      {q:"RAG workflows are ideal for:", a:"Evidence synthesis from trial registries", d:["Creative writing","Image generation","Code execution"], e:"Grounded in up-to-date material (Module 15).", c:3},
      {q:"Quantization trades:", a:"Precision for efficiency", d:["Accuracy for creativity","Size for safety","Speed for cost"], e:"With good calibration, performance stays close (Module 05).", c:3},
      {q:"LoRA reduces risk of:", a:"Catastrophic forgetting", d:["Hallucinations","Token limits","Temperature changes"], e:"Only adapters update (Module 05).", c:3},
      {q:"AI data centers affect:", a:"Speed and reliability of AI tools in clinic", d:["Only training","Only research","Only education"], e:"Outages cause lag at bedside (Module 15).", c:3},
      {q:"Multimodal fusion allows:", a:"Cross-modal tasks like retrieving images from text", d:["Text only tasks","Image only tasks","Audio only tasks"], e:"Unified representation (Module 15).", c:3},
      {q:"Agents support complex workflows like:", a:"Literature search, eligibility screening, table generation", d:["Only simple questions","Only image generation","Only safety checks"], e:"Loop until criteria met (Module 15).", c:3},
      {q:"RAG is ideal for:", a:"Evidence synthesis across publications", d:["Creative writing","Patient education","Code generation"], e:"Stays closer to source (Module 15).", c:3},

      // CLUSTER 4: Critical Evaluation, Bias, and Safety (20 questions)
      {q:"RLHF is:", a:"Reinforcement Learning from Human Feedback", d:["Random Learning from Humans","Real Learning from Hardware","Recursive Learning"], e:"Teaches the model to be helpful and safe (Module 14).", c:4},
      {q:"Catastrophic forgetting occurs when:", a:"A model loses older skills during new training", d:["Model gets too large","Tokens are lost","Safety filters fail"], e:"Like focusing on one subspecialty (Module 14).", c:4},
      {q:"Prompt injection is:", a:"Attacks that hide malicious instructions in text", d:["Improving prompt quality","Adding safety","Fine-tuning"], e:"Like hiding secret orders in a referral (Module 07).", c:4},
      {q:"Guardrails are:", a:"Rules and filters that block unsafe outputs", d:["Speed optimizers","Token counters","Style transfer tools"], e:"Like triage checks around AI (Module 07).", c:4},
      {q:"Hallucinations are especially risky in medicine because:", a:"They sound authoritative", d:["They are rare","They only happen in small models","They are easy to fix"], e:"Can lead to wrong diagnoses (Module 07).", c:4},
      {q:"Data privacy in AI means:", a:"PHI must stay in secure systems", d:["It's okay to use public tools","Only images are sensitive","Anonymized data is always safe"], e:"Never paste patient data into public AI (Module 15).", c:4},
      {q:"Emergent abilities are:", a:"New skills that appear at scale", d:["Planned features","Present in small models","Never appear"], e:"Like translation or code generation (Module 13).", c:4},
      {q:"RLHF can encourage the model to:", a:"Respect regulatory norms and acknowledge uncertainty", d:["Be more creative","Ignore safety","Give firm recommendations"], e:"Bakes in rater values (Module 14).", c:4},
      {q:"Prompt injection can threaten:", a:"Data integrity in automated chart review", d:["Model speed","Token count","Output style"], e:"Attackers can craft instructions in documents (Module 07).", c:4},
      {q:"Guardrails include:", a:"Content filters, policy rules, refusal behaviors", d:["Speed optimizers","Token counters","Style transfer"], e:"Keep model within safe use-cases (Module 07).", c:4},
      {q:"Hallucinations can appear as:", a:"Invented trial names or wrong sample sizes", d:["Correct citations","Real statistics","Accurate references"], e:"Always verify against primary sources (Module 07).", c:4},
      {q:"Data governance affects:", a:"How participant data is reused and protected", d:["Only model size","Only speed","Only cost"], e:"Regulators paying attention (Module 15).", c:4},
      {q:"Safety filters may:", a:"Refuse dosing questions or emphasize clinical judgment", d:["Always give dosing","Never refuse","Ignore guidelines"], e:"Cannot replace clinical judgment (Module 07).", c:4},
      {q:"Prompt injection security requires:", a:"Treating external text as untrusted", d:["Allowing all inputs","Using high temperature","Fine-tuning only"], e:"Sandboxing and filtering (Module 07).", c:4},
      {q:"RLHF bakes in:", a:"The values and biases of human raters", d:["Perfect safety","No bias","Only medical knowledge"], e:"Should be considered when deploying (Module 14).", c:4},
      {q:"Guardrails can introduce:", a:"False positives (blocking safe content)", d:["More hallucinations","Faster responses","Lower cost"], e:"Reduce risk but not perfect (Module 07).", c:4},
      {q:"Catastrophic forgetting is reduced by:", a:"Using adapters like LoRA", d:["Training from scratch","Increasing model size","Adding more data"], e:"Protects original knowledge (Module 05).", c:4},
      {q:"Emergent abilities can support:", a:"Unsupervised phenotyping", d:["Only supervised tasks","Only simple tasks","No clinical tasks"], e:"Even without explicit labels (Module 13).", c:4},
      {q:"Data privacy concerns include:", a:"Re-identification and breach risk", d:["Speed of inference","Token count","Output style"], e:"Even anonymous data can be re-identified (Module 15).", c:4},
      {q:"Best practice for safety:", a:"Treat all AI outputs as drafts to be checked", d:["Trust AI completely","Use AI for final orders","Never verify"], e:"Not a medical device (Module 07).", c:4},

      // CLUSTER 5: Workflow Design & Governance (20 questions)
      {q:"RAG workflows are:", a:"Retrieval + generation pipelines", d:["Single prompt only","Image generation","Code execution"], e:"Ideal for evidence synthesis (Module 15).", c:5},
      {q:"AI agents support:", a:"Complex workflows like literature search and cohort construction", d:["Only simple questions","Only image generation","Only safety checks"], e:"Loop until criteria met (Module 15).", c:5},
      {q:"Workflow orchestration means:", a:"Chaining multiple AI tools together", d:["Using one tool only","Manual processes","Data storage"], e:"Agents orchestrate (Module 15).", c:5},
      {q:"Human-in-the-loop patterns are:", a:"Essential for high-stakes decisions", d:["Optional","Never needed","Only for training"], e:"Person reviews before final use (Module 15).", c:5},
      {q:"Governance includes:", a:"Policies, auditing, and validation", d:["Only speed","Only cost","Only creativity"], e:"Responsible use in medicine (Module 15).", c:5},
      {q:"Evaluation frameworks are needed because:", a:"LLMs can sound confident but be wrong", d:["They are expensive","Models are always accurate","For marketing"], e:"Validate in your context (Module 15).", c:5},
      {q:"Best practice for clinical use:", a:"Never trust AI output without human verification", d:["Trust AI completely","Use AI for final orders","Let AI make decisions"], e:"AI is a tool, not replacement (Module 07).", c:5},
      {q:"Workflow design should include:", a:"Clear handoffs between AI and human", d:["AI only","Human only","No workflow"], e:"Human-in-the-loop patterns (Module 15).", c:5},
      {q:"Governance questions include:", a:"How participant data is reused and protected", d:["Only model size","Only speed","Only cost"], e:"Regulators paying attention (Module 15).", c:5},
      {q:"Evaluation frameworks for AI tools include:", a:"Testing in clinical and educational settings", d:["Only cost analysis","Only speed testing","Only marketing"], e:"Specific to your use case (Module 15).", c:5},
      {q:"Human-in-the-loop is required for:", a:"Adverse event detection or eligibility screening", d:["Only research","Only education","Never"], e:"High-stakes tasks (Module 15).", c:5},
      {q:"RAG workflows help with:", a:"Keeping answers up-to-date", d:["Increasing creativity","Reducing cost","Speeding up training"], e:"Pulls latest material (Module 15).", c:5},
      {q:"AI agents can support:", a:"Study meetings, protocol editing, cohort construction", d:["Only simple questions","Only image generation","Only safety"], e:"Interactive workflows (Module 15).", c:5},
      {q:"Governance affects:", a:"Data sovereignty and cross-border transfer", d:["Only model speed","Only token count","Only output style"], e:"Location of data centers matters (Module 15).", c:5},
      {q:"Best practice for evaluation:", a:"Match the actual deployed scale and context", d:["Test on small pilots only","Ignore scale","Use any model"], e:"Performance changes with scale (Module 13).", c:5},
      {q:"Human-in-the-loop patterns include:", a:"AI drafts, human reviews and approves", d:["AI finalizes","Human drafts only","No review"], e:"Best for clinical safety (Module 15).", c:5},
      {q:"Governance in clinical research raises questions about:", a:"Participant understanding of data use in AI", d:["Only model size","Only speed","Only cost"], e:"Informed consent for AI training (Module 15).", c:5},
      {q:"Workflow orchestration allows:", a:"Automated literature search to table generation", d:["Only manual search","Only simple questions","Only image generation"], e:"Full pipeline automation with human oversight (Module 15).", c:5},
      {q:"Evaluation frameworks help ensure:", a:"AI does not give regulatory advice or fabricate consent", d:["Faster responses","Lower cost","More creativity"], e:"Clear warnings and human review (Module 15).", c:5},
      {q:"RAG is ideal for:", a:"Evidence synthesis across publications", d:["Creative writing","Patient education","Code generation"], c:5}
    ];

    function shuffle(array) {
      return array.sort(() => Math.random() - 0.5);
    }

    function getRandomQuestions() {
      const selected = [];
      for (let cluster = 1; cluster <= 5; cluster++) {
        const clusterQs = questionBank.filter(q => q.c === cluster);
        selected.push(...shuffle(clusterQs).slice(0, 4));
      }
      return shuffle(selected);
    }

    const questions = getRandomQuestions();
    const form = document.getElementById('quiz');

    questions.forEach((q, i) => {
      const allAnswers = [q.a, ...q.d];
      const shuffled = shuffle(allAnswers);
      const correctIndex = shuffled.indexOf(q.a);

      const div = document.createElement('div');
      div.className = 'bg-white rounded-2xl shadow-md p-6 border border-slate-200';
      div.innerHTML = `
        <p class="question-text text-base mb-5">${i+1}. ${q.q}</p>
        <div class="grid grid-cols-1 md:grid-cols-2 gap-3">
          ${shuffled.map((ans, j) => `
            <label class="option">
              <input type="radio" name="q${i}" value="${j === correctIndex ? 'correct' : 'wrong'}">
              <span class="answer-text">${ans}</span>
            </label>
          `).join('')}
        </div>
      `;
      form.appendChild(div);
    });

    form.innerHTML += `
      <div class="text-center mt-16">
        <button type="submit" class="px-16 py-6 bg-indigo-600 text-white text-2xl font-bold rounded-full shadow-2xl hover:bg-indigo-700 transform hover:scale-105 transition">
          Generate My Fluency Profile →
        </button>
      </div>
    `;

    form.onsubmit = e => {
      e.preventDefault();
      const scores = [0,0,0,0,0];
      let wrong = [];

      questions.forEach((q, i) => {
        const selected = form.querySelector(`input[name="q${i}"]:checked`);
        if (selected && selected.value === "correct") {
          scores[q.c - 1]++;
        } else if (selected) {
          wrong.push({q: q.q, your: selected.nextElementSibling.textContent.trim(), correct: q.a, exp: q.e});
        }
      });

      const percentages = scores.map(s => Math.round((s / 4) * 100));
      const avg = Math.round(percentages.reduce((a,b) => a + b) / 5);

      document.getElementById('results').classList.remove('hidden');
      document.getElementById('score').textContent = `${avg}% Fluency`;
      document.getElementById('message').textContent = avg >= 90 ? "Outstanding mastery!" : avg >= 70 ? "Strong understanding!" : "Great start — keep learning!";

      new Chart(document.getElementById('radar'), {
        type: 'radar',
        data: {
          labels: ["Prompt Mastery","Model Fundamentals","Practical Use Cases","Safety & Evaluation","Workflow & Governance"],
          datasets: [{ data: percentages, backgroundColor: 'rgba(99,102,241,0.15)', borderColor: '#6366f1', borderWidth: 4, pointBackgroundColor: '#4338ca' }]
        },
        options: {
          scales: { r: { min: 0, max: 100, ticks: { stepSize: 20, font: { family: 'Roboto', weight: 400 } } } },
          plugins: { legend: { display: false } },
          elements: { line: { tension: 0.3 } }
        }
      });

      const focus = percentages.map((p,i) => p < 70 ? ["Prompt Mastery","Model Fundamentals","Practical Use Cases","Safety & Evaluation","Workflow & Governance"][i] : null).filter(Boolean);
      document.getElementById('focus-areas').innerHTML = focus.length
        ? `<p class="text-base text-slate-700">Recommended focus: <strong>${focus.join(', ')}</strong></p><p class="text-base text-slate-700 mt-3">These modules will help you most right now.</p>`
        : `<p class="text-base text-slate-700">Outstanding! Excellent fluency across all domains.</p>`;

      const review = document.getElementById('review');
      review.innerHTML = wrong.length === 0
        ? `<p class="text-base text-slate-700">Perfect score! You got everything right.</p>`
        : wrong.map(w => `
          <div class="bg-red-50 p-6 rounded-xl border-l-4 border-red-500">
            <p class="question-text text-base">${w.q}</p>
            <p class="answer-text text-base text-red-700 mt-3">You answered: ${w.your}</p>
            <p class="answer-text text-base text-green-700 font-medium mt-2">Correct: ${w.correct}</p>
            <p class="answer-text text-base text-slate-600 italic mt-3">${w.exp}</p>
          </div>
        `).join('');

      document.getElementById('results').scrollIntoView({ behavior: 'smooth', block: 'center' });
    };
  </script>
</body>
</html>
