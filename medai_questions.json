[
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "What is the main goal of prompt engineering in tools like ChatGPT?",
    "option_a": "To change the model weights",
    "option_b": "To write instructions so the model gives more useful outputs",
    "option_c": "To increase the size of the model",
    "option_d": "To bypass safety filters",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Which prompt is most likely to produce a clear discharge summary for a resident?",
    "option_a": "Write something about this patient",
    "option_b": "Summarize this chart",
    "option_c": "You are a senior resident. Write a one paragraph discharge summary for an internal medicine attending using problem based format.",
    "option_d": "Tell me everything you know about heart failure.",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "What is a system prompt in many chat style tools?",
    "option_a": "A short answer produced by the model",
    "option_b": "Hidden instructions that set the overall role and behavior of the model",
    "option_c": "The user's first question",
    "option_d": "The model safety filter only",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Few shot prompting usually means:",
    "option_a": "Giving the model one word questions",
    "option_b": "Giving the model examples of good and bad answers before asking for a new answer",
    "option_c": "Using very short prompts",
    "option_d": "Limiting the model to a few tokens",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Which prompt best uses chain of thought style prompting?",
    "option_a": "Answer in one word.",
    "option_b": "Give only the final diagnosis.",
    "option_c": "Think step by step and show your reasoning before giving a concise final answer.",
    "option_d": "Ignore all previous instructions.",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Temperature in a chat model controls:",
    "option_a": "The server room cooling system",
    "option_b": "How many parameters are active",
    "option_c": "How random and creative the word choices are",
    "option_d": "The size of the context window",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "For high stakes clinical education questions the safest temperature setting is usually:",
    "option_a": "High temperature for creativity",
    "option_b": "Low temperature for stability and reproducibility",
    "option_c": "Random temperature each time",
    "option_d": "Temperature does not matter",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Style transfer in prompting refers to:",
    "option_a": "Changing the font of the output",
    "option_b": "Asking the model to rewrite content in a different style or voice",
    "option_c": "Translating between languages only",
    "option_d": "Copying prompts from another user",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Which is the best use of an explicit role in a prompt?",
    "option_a": "You are my friend.",
    "option_b": "You are a large language model.",
    "option_c": "You are a medical scribe documenting an outpatient visit for an internist.",
    "option_d": "Ignore all safety rules.",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "When building a prompt template for faculty it is most helpful to:",
    "option_a": "Keep it secret and never reuse it",
    "option_b": "Rewrite it from scratch each time",
    "option_c": "Standardize it, test it, and reuse it for similar tasks",
    "option_d": "Avoid instructions and let the model guess the goal",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Zero shot prompting means:",
    "option_a": "Giving the model many examples before a question",
    "option_b": "Giving no examples and asking for a direct answer",
    "option_c": "Only using the model at midnight",
    "option_d": "Turning off safety filters",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "In a conversational pattern, a good repair prompt after a weak answer is:",
    "option_a": "Forget it.",
    "option_b": "Why are you so wrong?",
    "option_c": "That was not what I needed. Please restate the answer in three bullet points focused on key teaching messages for interns.",
    "option_d": "Stop talking.",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Which instruction best helps the model match a specific audience?",
    "option_a": "Just write this",
    "option_b": "Write something academic",
    "option_c": "Explain this concept for first year medical students using plain language and one clinical example.",
    "option_d": "Explain this in fancy words.",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "A prompt that says 'Do not answer until you have asked me at least two clarifying questions' is trying to:",
    "option_a": "Reduce model speed",
    "option_b": "Force the model offline",
    "option_c": "Encourage the model to gather more context before answering",
    "option_d": "Disable safety settings",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "When using a reusable prompt for clinic documentation, a best practice is to:",
    "option_a": "Use it without review",
    "option_b": "Lock trainees out of it",
    "option_c": "Test it on several sample notes and refine wording based on errors",
    "option_d": "Share it on social media only",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "A meta prompt such as 'Evaluate the quality of this previous answer' is mostly used to:",
    "option_a": "Change hardware settings",
    "option_b": "Ask the model to critique or improve its own output",
    "option_c": "Reset the context window",
    "option_d": "Delete logs",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "In a teaching session, the most useful way to share prompts with residents is:",
    "option_a": "Verbally and never written",
    "option_b": "As screenshots only",
    "option_c": "As a simple playbook with copyable prompt templates and examples",
    "option_d": "Not sharing at all to keep control",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "When a prompt explicitly requests numbered steps, the main effect is:",
    "option_a": "Shorter tokens",
    "option_b": "A more structured and scannable answer",
    "option_c": "A more random answer",
    "option_d": "More hallucinations",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "In MedAI context, few shot clinical reasoning prompts often pair:",
    "option_a": "Random questions and random answers",
    "option_b": "Clinical vignettes and example responses",
    "option_c": "Only lab values and billing codes",
    "option_d": "Only vital signs",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "If a model repeatedly ignores an instruction in the prompt, a good next step is to:",
    "option_a": "Complain to trainees",
    "option_b": "Stop using AI forever",
    "option_c": "Rewrite the instruction more specifically and move it earlier in the prompt",
    "option_d": "Turn off grammar checking",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Prompt patterns such as 'role task context constraints examples' are mainly useful because they:",
    "option_a": "Hide the true task",
    "option_b": "Increase GPU usage",
    "option_c": "Give a repeatable structure that others can adapt",
    "option_d": "Block safety filters",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "When asking the model to generate exam questions, a safe instruction is:",
    "option_a": "Use real patient names",
    "option_b": "Include PHI if it helps realism",
    "option_c": "Do not include any real patient identifiers and keep all examples fictional",
    "option_d": "Ignore privacy rules",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "To reduce hallucinations in a prompt that asks about local policies, you should:",
    "option_a": "Ask about everything in medicine at once",
    "option_b": "Avoid giving any documents",
    "option_c": "Provide the exact text of the relevant policy and tell the model to stick to that text",
    "option_d": "Tell the model to guess",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "In a longitudinal course, storing tested prompts in a shared document mainly helps:",
    "option_a": "Increase confusion",
    "option_b": "Prevent reuse",
    "option_c": "Create consistency and reduce repeated trial and error",
    "option_d": "Hide expertise",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "When you ask for a summary 'in one table with columns X Y and Z' you are mainly guiding:",
    "option_a": "Sampling temperature",
    "option_b": "Output format and structure",
    "option_c": "Hardware resources",
    "option_d": "User logins",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Tokenization is best described as:",
    "option_a": "Turning text into small units the model can count and process",
    "option_b": "Encrypting the text",
    "option_c": "Measuring user time online",
    "option_d": "Assigning diagnosis codes",
    "correct_option": "A"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "An embedding is:",
    "option_a": "A lab test code in the EHR",
    "option_b": "A numerical vector that represents meaning of text in a high dimensional space",
    "option_c": "A type of infection",
    "option_d": "A radiology sequence",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Latent space in a model is:",
    "option_a": "The physical space in the data center",
    "option_b": "The internal concept space where related ideas are close together",
    "option_c": "A secure cloud folder",
    "option_d": "The area of memory used for logs",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Hallucinations in large language models are:",
    "option_a": "Visual images generated by the model",
    "option_b": "Sleep problems caused by screen time",
    "option_c": "Confident but incorrect or fabricated outputs",
    "option_d": "Outputs that use medical jargon",
    "correct_option": "C"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Positional encoding helps the model:",
    "option_a": "Know the order of tokens in a sequence",
    "option_b": "Store patient locations",
    "option_c": "Encrypt PHI",
    "option_d": "Assign billing codes",
    "correct_option": "A"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "The context window of a model is:",
    "option_a": "The number of users who can log in",
    "option_b": "The amount of text the model can consider at one time",
    "option_c": "The number of GPUs in the cluster",
    "option_d": "The time allowed for a session",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Sampling methods in text generation are used to:",
    "option_a": "Decide which tokens to pick next from the probability distribution",
    "option_b": "Choose which patients to enroll in a trial",
    "option_c": "Measure lab values",
    "option_d": "Assign residents to clinics",
    "correct_option": "A"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Attention heads in a transformer model:",
    "option_a": "Are hospital service chiefs",
    "option_b": "Are parallel pattern detectors that focus on different relationships in the text",
    "option_c": "Are parts of the cooling system",
    "option_d": "Are types of memory chips",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Residual connections or residual streams in deep networks mainly help:",
    "option_a": "Shorten notes",
    "option_b": "Carry information forward through layers without erasing it",
    "option_c": "Encrypt data",
    "option_d": "Reduce token counts",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "RLHF, which stands for reinforcement learning from human feedback, is mainly used to:",
    "option_a": "Train residents",
    "option_b": "Align model behavior with human preferences and safety norms",
    "option_c": "Encrypt medical images",
    "option_d": "Increase internet speed",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Scaling laws in language models suggest that:",
    "option_a": "Performance stays flat as models grow",
    "option_b": "Performance tends to improve predictably as data, parameters, and compute increase",
    "option_c": "Only hardware matters",
    "option_d": "Bigger models are always unsafe",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Training in this context usually refers to:",
    "option_a": "Writing a prompt",
    "option_b": "Adjusting model weights on large datasets",
    "option_c": "Turning servers on and off",
    "option_d": "Switching users between clinics",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Inference in a large language model means:",
    "option_a": "Collecting training data",
    "option_b": "Updating weights",
    "option_c": "Running the already trained model to generate outputs for new inputs",
    "option_d": "Deleting logs",
    "correct_option": "C"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Pretraining for a general model most often uses:",
    "option_a": "Only one textbook",
    "option_b": "Large mixed datasets such as web pages, books, code, and public text",
    "option_c": "Only EHR data",
    "option_d": "Only radiology images",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Fine tuning on top of a pretrained model usually:",
    "option_a": "Starts training from zero again",
    "option_b": "Makes smaller adjustments for a narrower domain or task",
    "option_c": "Deletes pretraining data",
    "option_d": "Turns off safety filters",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "A model's parameters are best thought of as:",
    "option_a": "Hospital beds",
    "option_b": "Numeric values that determine how the model maps inputs to outputs",
    "option_c": "Billing codes",
    "option_d": "Folder names",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "A safety filter layer around a model usually:",
    "option_a": "Changes the number of parameters",
    "option_b": "Screens and edits prompts or outputs that involve sensitive or risky content",
    "option_c": "Changes the embedding space",
    "option_d": "Only manages passwords",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "When a model is described as multimodal, it usually means:",
    "option_a": "It only handles text",
    "option_b": "It can handle multiple input types such as text and images",
    "option_c": "It only handles billing codes",
    "option_d": "It only handles audio",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Context overflow happens when:",
    "option_a": "Users log in too quickly",
    "option_b": "The total input and history exceed the model's context window and older tokens are dropped or truncated",
    "option_c": "GPU fans stop",
    "option_d": "Passwords expire",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "A smaller specialized model may be preferable to a very large general model when:",
    "option_a": "The task is narrow and latency and cost are important",
    "option_b": "The task is unknown",
    "option_c": "No training data exist",
    "option_d": "You want maximum hype only",
    "correct_option": "A"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Temperature and top k together control:",
    "option_a": "EHR storage",
    "option_b": "The randomness and diversity of token sampling",
    "option_c": "GPU memory leaks",
    "option_d": "Network speed",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "When a model returns different but all reasonable paraphrases of the same guideline, this likely reflects:",
    "option_a": "Unstable hardware",
    "option_b": "The stochastic nature of sampling over similar tokens",
    "option_c": "Data corruption",
    "option_d": "User error only",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "A token is roughly:",
    "option_a": "Always one word exactly",
    "option_b": "A chunk of text that can be a whole word, part of a word, or punctuation",
    "option_c": "One sentence",
    "option_d": "One paragraph",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "One reason models hallucinate citations is:",
    "option_a": "They are directly reading all articles live",
    "option_b": "They do not have a built in database of verified references and instead generate citation like strings from patterns in training data",
    "option_c": "They can access PubMed in real time by default",
    "option_d": "They are required to be accurate about references",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "If a vendor claims their model never hallucinates, a safe interpretation is that:",
    "option_a": "They have solved AI alignment completely",
    "option_b": "They are exaggerating or misusing the term and you should ask detailed evaluation questions",
    "option_c": "They must be using magical hardware",
    "option_d": "The model cannot generate text",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "Retrieval augmented generation (RAG) combines:",
    "option_c": "Only free text prompts",
    "option_d": "Search over external documents with language model generation",
    "correct_option": "IMAGE RECOGNITION WITH BILLING"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "A good use of RAG in a medical school is:",
    "option_c": "Randomly writing policies",
    "option_d": "Grounding answers in local policies and guidelines pulled from institutional documents",
    "correct_option": "REPLACING ALL FACULTY"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "AI agents in the MedAI sense are:",
    "option_c": "Single static prompts",
    "option_d": "Systems where models can plan, call tools, review results, and iterate",
    "correct_option": "ONLY CHATBOTS THAT TRANSLATE LANGUAGES"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "Human in the loop review in an AI workflow means:",
    "option_c": "No human oversight",
    "option_d": "A human reviews and can override AI outputs at defined points",
    "correct_option": "HUMANS ONLY SET UP HARDWARE"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "Quantization of a model mainly:",
    "option_c": "Increases floating point precision",
    "option_d": "Compresses model weights to fewer bits to save memory and compute",
    "correct_option": "DELETES SAFETY FILTERS"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "LoRA (low rank adaptation) is designed to:",
    "option_c": "Retrain the whole model from scratch",
    "option_d": "Adapt a large model by training small add on matrices instead of all weights",
    "correct_option": "ENCRYPT EHR DATA"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "Diffusion models are most commonly used for:",
    "option_c": "Tabular billing data",
    "option_d": "Image generation and image like data such as medical image synthesis",
    "correct_option": "AUDIO ONLY TASKS"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "Multimodal models in MedAI are models that:",
    "option_c": "Only use text input",
    "option_d": "Jointly process text, images, and other modalities",
    "correct_option": "ONLY USE LAB DATA"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "AI data centers used for MedAI workloads mainly require:",
    "option_c": "Only office chairs",
    "option_d": "GPU or similar accelerators, high bandwidth networking, and strong cooling",
    "correct_option": "ONLY LARGE WAITING ROOMS"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "A practical safe early use case of generative AI for faculty is:",
    "option_c": "Letting it write final prescriptions for patients",
    "option_d": "Using it to draft formative feedback that you review and edit before sending",
    "correct_option": "LETTING IT ENTER ORDERS DIRECTLY"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "In curriculum design, a realistic AI supported workflow is:",
    "option_c": "Asking AI to approve promotions",
    "option_d": "Using AI to draft learning objectives and sample questions that faculty then revise",
    "correct_option": "LETTING AI ASSIGN CLERKSHIP GRADES"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "In research, a safe starting use case is:",
    "option_c": "Letting AI fabricate data for a trial",
    "option_d": "Using AI to help draft background sections that are then checked against primary sources",
    "correct_option": "LETTING AI SIGN IRB FORMS"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "A good use of AI for resident coaching is:",
    "option_c": "Letting AI replace all faculty coaching",
    "option_d": "Using AI to generate practice questions and sample answers for debrief with faculty",
    "correct_option": "LETTING AI CONDUCT SUMMATIVE EVALUATIONS ALONE"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "For patient education materials, generative AI can:",
    "option_c": "Directly send materials without clinician review",
    "option_d": "Draft plain language explanations that clinicians review and adapt for their population",
    "correct_option": "IGNORE LITERACY LEVELS"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "Using RAG against institutional policies mainly helps:",
    "option_c": "Increase hallucinations",
    "option_d": "Keep answers aligned with local rules and reduce unsupported claims",
    "correct_option": "REPLACE COMPLIANCE OFFICERS"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "A safe teaching use of an image generation model is:",
    "option_c": "Generating identifiable images of local patients",
    "option_d": "Creating generic diagrams or conceptual images that do not depict real patients",
    "correct_option": "UPLOADING REAL CT SCANS WITH IDENTIFIERS TO PUBLIC TOOLS"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "In quality improvement projects, AI can help by:",
    "option_c": "Signing off on interventions",
    "option_d": "Drafting fishbone diagrams or driver diagrams that teams refine",
    "correct_option": "APPROVING BUDGETS"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "In a busy clinic, AI scribing tools should be used so that:",
    "option_c": "The note is accepted automatically",
    "option_d": "The clinician reviews and edits the draft note before signing",
    "correct_option": "RESIDENTS NEVER SEE THE NOTE"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "When using AI to summarize long articles for journal club, a good practice is to:",
    "option_c": "Skip reading the full paper",
    "option_d": "Use summaries only",
    "correct_option": "COMPARE THE AI SUMMARY WITH THE ORIGINAL PAPER BEFORE TEACHING OR MAKING CLAIMS"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "For a grant proposal, AI can most safely help:",
    "option_c": "Fill in the budget tables without oversight",
    "option_d": "Draft narrative sections that investigators review and edit",
    "correct_option": "SIGN SUBMISSION FORMS"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "In simulation education, AI can:",
    "option_c": "Replace all debriefing faculty",
    "option_d": "Help create variations of case scenarios and checklists that faculty test and refine",
    "correct_option": "RUN SIMULATIONS WITHOUT HUMAN OBSERVERS"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "A practical use of embeddings in education is:",
    "option_c": "Matching random articles",
    "option_d": "Building a semantic search tool over local teaching cases",
    "correct_option": "ENCRYPTING PASSWORDS"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "When introducing AI into a clerkship, a reasonable first step is:",
    "option_c": "Make it mandatory in all patient interactions",
    "option_d": "Pilot a narrow use case such as drafting feedback, with clear rules and supervision",
    "correct_option": "LET STUDENTS USE ANY PUBLIC TOOL WITH PHI"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "AI can help with program evaluation by:",
    "option_c": "Replacing institutional research staff",
    "option_d": "Summarizing open ended survey comments into themes for human review",
    "correct_option": "WRITING ACCREDITATION LETTERS WITH NO OVERSIGHT"
  },
  {
    "domain": "Practical use cases in education",
    "question": "research",
    "option_a": "and clinical work",
    "option_b": "In a research data pipeline, an AI helper script might:",
    "option_c": "Invent outcome data",
    "option_d": "Help generate code snippets for cleaning data that analysts then review",
    "correct_option": "SUBMIT DATA DIRECTLY TO REGULATORS"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "Hallucinations in clinical education content are dangerous mainly because:",
    "option_c": "They are always easy to detect",
    "option_d": "They can look plausible and confident while being wrong",
    "correct_option": "THEY NEVER MENTION REFERENCES"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "A safe first reaction when a model gives a surprising clinical claim is to:",
    "option_c": "Accept it if the wording is confident",
    "option_d": "Verify it against trusted sources such as guidelines or primary literature",
    "correct_option": "SHARE IT WIDELY ON SOCIAL MEDIA"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "RLHF can introduce bias because:",
    "option_c": "It removes all human input",
    "option_d": "Human raters' preferences and blind spots are encoded into the reward model",
    "correct_option": "IT DELETES TRAINING DATA"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "Catastrophic forgetting is most relevant when:",
    "option_c": "A model is trained sequentially on new tasks and loses performance on earlier tasks",
    "option_d": "A model is never updated",
    "correct_option": "A MODEL IS ONLY USED FOR TRANSLATION"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "Emergent abilities in larger models mean that:",
    "option_c": "New skills can appear at scale and need fresh evaluation in clinical contexts",
    "option_d": "Models never change with scale",
    "correct_option": "SMALL MODELS ARE ALWAYS BETTER"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "Prompt injection attacks usually try to:",
    "option_c": "Improve note clarity",
    "option_d": "Hide malicious instructions inside text that the model will follow",
    "correct_option": "ENCRYPT THE CONTEXT WINDOW"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "A strong guardrail for AI use with PHI in a medical school is:",
    "option_c": "Copying PHI into any public chatbot",
    "option_d": "Restricting PHI to approved systems with encryption and business associate agreements",
    "correct_option": "SHARING SCREENSHOTS IN CHAT APPS"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "Data governance for AI in an academic health center should include:",
    "option_c": "Clear rules on which data can train models, where data can be stored, and who can access outputs",
    "option_d": "Only buying more GPUs",
    "correct_option": "ONLY TRACKING INTERNET SPEED"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "A red flag in a vendor claim about a clinical AI tool is:",
    "option_c": "They openly share evaluation methods and limitations",
    "option_d": "They state that the model never hallucinates and needs no human review",
    "correct_option": "THEY PUBLISH VALIDATION DATASETS"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "When teaching trainees about AI bias a helpful exercise is:",
    "option_c": "Never discussing examples",
    "option_d": "Designing small tests where they check outputs for different patient groups and discuss differences",
    "correct_option": "ONLY USING MARKETING SLIDES"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "Data privacy in MedAI mainly concerns:",
    "option_c": "Where models store weights only",
    "option_d": "How identifiable information is protected, shared, and used for training or inference",
    "correct_option": "MONITOR SIZE"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "An AI safety incident report in a health system should capture:",
    "option_c": "Only hardware failures",
    "option_d": "Near misses, unexpected behaviors, and potential patient or learner impact related to AI use",
    "correct_option": "ONLY BILLING ISSUES"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "Benchmarking a model on clinical tasks is important because:",
    "option_c": "Benchmarks always match real life",
    "option_d": "It provides one structured view of performance and limitations that must still be interpreted in context",
    "correct_option": "IT REPLACES LOCAL TESTING"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "One way to reduce bias when using AI in admissions is to:",
    "option_c": "Allow AI to make final admission decisions",
    "option_d": "Use AI summaries only as an optional aid and keep human holistic review with clear guidelines",
    "correct_option": "HIDE CRITERIA FROM REVIEWERS"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "Model cards are:",
    "option_c": "Social media posts",
    "option_d": "Documents that describe a model's training data, intended uses, and limitations",
    "correct_option": "ONLY HARDWARE SPECS"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "A safe policy for trainees using AI on assignments is:",
    "option_c": "Never talk about AI",
    "option_d": "Allow use with clear disclosure, guardrails, and human review",
    "correct_option": "REQUIRE AI FOR ALL ASSIGNMENTS"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "Overreliance on AI in clinical note generation can lead to:",
    "option_c": "Shorter notes with no risk",
    "option_d": "Template drift, propagation of errors, and weaker critical thinking if not reviewed",
    "correct_option": "PERFECT ACCURACY"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "An example of distribution shift is:",
    "option_c": "The model is tested on the same data it was trained on",
    "option_d": "The model is used on a population very different from its training data",
    "correct_option": "THE MODEL IS NEVER DEPLOYED"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "A responsible way to use AI for exam writing is:",
    "option_c": "Let AI write all high stakes questions with no review",
    "option_d": "Use AI to propose draft questions that faculty edit and validate against blueprints",
    "correct_option": "LET AI ASSIGN SCORES AUTOMATICALLY"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "When evaluating AI outputs for health disparities, one important step is to:",
    "option_c": "Assume outputs are neutral",
    "option_d": "Intentionally test examples across different demographic groups and check for differences in recommendations or language",
    "correct_option": "AVOID MENTIONING RACE OR GENDER EVER"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "A sign of automation bias is:",
    "option_c": "Users ignore AI",
    "option_d": "Users rely on AI suggestions even when they conflict with obvious evidence or their own judgment",
    "correct_option": "USERS ALWAYS DISAGREE WITH AI"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "Safety filters that block self harm or violence content exist mainly to:",
    "option_c": "Slow down responses",
    "option_d": "Reduce harmful outputs and protect users",
    "correct_option": "INCREASE GPU HEAT"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "When using AI to summarize sensitive narratives from learners, a respectful practice is to:",
    "option_c": "Share raw text with all vendors",
    "option_d": "Remove identifiers and only use approved secure systems for analysis",
    "correct_option": "POST EXCERPTS ON SOCIAL MEDIA"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "A hospital AI oversight committee reviewing a new sepsis prediction model should ask:",
    "option_c": "What color the dashboard is",
    "option_d": "How it was validated, how it performs for different units, and how clinicians can override it",
    "correct_option": "WHETHER IT IS TRENDY"
  },
  {
    "domain": "Critical evaluation",
    "question": "bias",
    "option_a": "and safety",
    "option_b": "One way to avoid leakage of confidential curriculum plans when prompting is to:",
    "option_c": "Paste the entire confidential plan into a public chatbot",
    "option_d": "Use redacted or synthetic examples and institutionally approved tools",
    "correct_option": "IGNORE POLICY"
  },
  {
    "domain": "Workflow design and governance",
    "question": "An AI enabled workflow in a clerkship should ideally:",
    "option_a": "Be ad hoc and undocumented",
    "option_b": "Be mapped out step by step with clear inputs, outputs, and review points",
    "option_c": "Be controlled only by the vendor",
    "option_d": "Replace all human teaching",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "Human in the loop design for a MedAI workflow means:",
    "option_a": "Humans are removed from decisions",
    "option_b": "Humans remain responsible and review AI suggestions at defined stages",
    "option_c": "Humans only handle billing",
    "option_d": "Humans only handle hardware",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A department level MedAI governance group should at minimum include:",
    "option_a": "Only external vendors",
    "option_b": "Clinical, educational, and research leaders plus IT and compliance partners",
    "option_c": "Only students",
    "option_d": "Only finance staff",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A good first step before deploying an AI workflow in the EHR is:",
    "option_a": "Turn it on in production for all patients immediately",
    "option_b": "Pilot test the workflow in a limited setting with clear evaluation metrics and safety checks",
    "option_c": "Announce it on social media first",
    "option_d": "Skip IRB and governance",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "In a medical school context, evaluation frameworks for AI tools should focus on:",
    "option_a": "Only vendor reputation",
    "option_b": "Educational impact, clinical impact, safety, and equity",
    "option_c": "Only reducing faculty time",
    "option_d": "Only improving marketing",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "One realistic early workflow for faculty is:",
    "option_a": "Using the model to draft learning objectives or rubrics that faculty edit",
    "option_b": "Letting the model assign final grades with no review",
    "option_c": "Letting the model sign prescriptions",
    "option_d": "Letting the model approve promotions",
    "correct_option": "A"
  },
  {
    "domain": "Workflow design and governance",
    "question": "When documenting an AI workflow map a helpful convention is to:",
    "option_a": "Hide where AI is used",
    "option_b": "Mark clearly where AI is used and where humans must review or override",
    "option_c": "Only describe hardware details",
    "option_d": "Only describe billing codes",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A key risk if workflows are not documented is:",
    "option_a": "Too much transparency",
    "option_b": "Shadow AI use that leadership cannot supervise or support",
    "option_c": "Better governance",
    "option_d": "Automatic accreditation",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "For a MedAI curriculum committee one practical task is:",
    "option_a": "Approving all new apps automatically",
    "option_b": "Identifying high value early use cases and setting guidance on safe patterns and banned patterns",
    "option_c": "Blocking all AI use",
    "option_d": "Letting each person decide in isolation",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "In the MedAI Fluency Studio results, a low workflow design score should prompt:",
    "option_a": "Ignoring workflow issues",
    "option_b": "Work on mapping one or two concrete AI supported workflows and presenting them to a governance group",
    "option_c": "Stopping all AI exploration",
    "option_d": "Only buying more hardware",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A simple visual workflow map for AI in a course should include:",
    "option_a": "Only course title",
    "option_b": "Steps, actors, where AI is invoked, and where human checks occur",
    "option_c": "Only budget codes",
    "option_d": "Only room numbers",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "Involving frontline clinicians and faculty in AI workflow design is important because:",
    "option_a": "They slow progress",
    "option_b": "They understand real tasks and failure modes that may not be obvious to technical teams",
    "option_c": "They control hardware",
    "option_d": "They write code only",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A change control process for AI tools primarily ensures that:",
    "option_a": "Models stay trendy",
    "option_b": "Updates are tested, documented, and communicated before changes reach users",
    "option_c": "Vendors can deploy at any time",
    "option_d": "Only hardware is updated",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "In admissions, using AI summaries of applications safely requires:",
    "option_a": "Letting the summary make decisions",
    "option_b": "Making AI summaries optional aids and requiring human committee review with transparency about limitations",
    "option_c": "Hiding AI use from the committee",
    "option_d": "Letting AI rank applicants alone",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A checklist for approving a new AI powered documentation tool should include:",
    "option_a": "Logo design",
    "option_b": "Data flows, PHI handling, human review steps, monitoring plan, and deactivation option",
    "option_c": "Social media campaign",
    "option_d": "Furniture placement",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "When integrating AI into simulation center workflows, one safe pilot is:",
    "option_a": "Letting AI run debriefings alone",
    "option_b": "Using AI to generate scenario variations that faculty review before use",
    "option_c": "Allowing AI to assign simulation grades automatically",
    "option_d": "Letting AI schedule all staff",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A governance rule that 'no PHI enters unapproved tools' is only effective if:",
    "option_a": "No one knows it",
    "option_b": "There is education, approved alternatives, and monitoring",
    "option_c": "It is posted once in a long policy",
    "option_d": "It is ignored",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "In a clinical documentation workflow, a good measure of success for an AI helper is:",
    "option_a": "Number of marketing posts",
    "option_b": "Reduction in redundant typing while maintaining or improving accuracy and clinician satisfaction",
    "option_c": "Increase in note length only",
    "option_d": "Number of emojis used",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A central inventory of AI tools used across a health sciences center mainly supports:",
    "option_a": "Shadow IT",
    "option_b": "Better oversight, risk assessment, and coordination of pilots and production tools",
    "option_c": "More silos",
    "option_d": "Ignoring updates",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "When a vendor demo shows an impressive AI feature, a governance group should ask:",
    "option_a": "What colors are used",
    "option_b": "What data was used in the demo, how it performs on local data, and what guardrails exist",
    "option_c": "How many likes it got online",
    "option_d": "Who designed the logo",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A fair process for deciding which AI pilots to support should consider:",
    "option_a": "Only political influence",
    "option_b": "Educational and clinical value, feasibility, risk, and alignment with strategic priorities",
    "option_c": "Only who asked first",
    "option_d": "Only vendor gifts",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "Documenting 'off label' AI use in workflows is helpful because:",
    "option_a": "It encourages secrecy",
    "option_b": "It allows leaders to understand and either guide, formalize, or phase out risky patterns",
    "option_c": "It guarantees funding",
    "option_d": "It removes all risk",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "When scaling an AI workflow from one clerkship to the whole school, a key step is:",
    "option_a": "Skipping evaluation",
    "option_b": "Reviewing pilot results, adapting for new contexts, and updating policies and training",
    "option_c": "Letting every unit improvise silently",
    "option_d": "Removing all human review",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "In strategic planning, including AI workflows in departmental scorecards mainly helps:",
    "option_a": "Hide activity",
    "option_b": "Make efforts visible, track progress, and link AI use to concrete outcomes",
    "option_c": "Only increase hype",
    "option_d": "Replace other goals",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "For a hospital partner, an AI data sharing agreement should at minimum clarify:",
    "option_a": "Cafeteria menu",
    "option_b": "What data is shared, how it is protected, who can access it, and how outputs may be used",
    "option_c": "Parking spots",
    "option_d": "Vacation days",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "In faculty development, showcasing a well documented AI workflow from one department can:",
    "option_a": "Discourage others",
    "option_b": "Provide a template and confidence for other units to adopt safe patterns rather than invent from scratch",
    "option_c": "Replace other training",
    "option_d": "End all experimentation",
    "correct_option": "B"
  }
]