[
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "What is the main goal of prompt engineering in tools like ChatGPT?",
    "option_a": "To change the model weights",
    "option_b": "To write instructions so the model gives more useful outputs",
    "option_c": "To increase the size of the model",
    "option_d": "To bypass safety filters",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Which prompt is most likely to produce a clear discharge summary for a resident?",
    "option_a": "Write something about this patient",
    "option_b": "Summarize this chart",
    "option_c": "You are a senior resident. Write a one paragraph discharge summary for an internal medicine attending using problem based format.",
    "option_d": "Tell me everything you know about heart failure.",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "What is a system prompt in many chat style tools?",
    "option_a": "A short answer produced by the model",
    "option_b": "Hidden instructions that set the overall role and behavior of the model",
    "option_c": "The user's first question",
    "option_d": "The model safety filter only",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Few shot prompting usually means:",
    "option_a": "Giving the model one word questions",
    "option_b": "Giving the model examples of good and bad answers before asking for a new answer",
    "option_c": "Using very short prompts",
    "option_d": "Limiting the model to a few tokens",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Which prompt best uses chain of thought style prompting?",
    "option_a": "Answer in one word.",
    "option_b": "Give only the final diagnosis.",
    "option_c": "Think step by step and show your reasoning before giving a concise final answer.",
    "option_d": "Ignore all previous instructions.",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Temperature in a chat model controls:",
    "option_a": "The server room cooling system",
    "option_b": "How many parameters are active",
    "option_c": "How random and creative the word choices are",
    "option_d": "The size of the context window",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "For high stakes clinical education questions the safest temperature setting is usually:",
    "option_a": "High temperature for creativity",
    "option_b": "Low temperature for stability and reproducibility",
    "option_c": "Random temperature each time",
    "option_d": "Temperature does not matter",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Style transfer in prompting refers to:",
    "option_a": "Changing the font of the output",
    "option_b": "Asking the model to rewrite content in a different style or voice",
    "option_c": "Translating between languages only",
    "option_d": "Copying prompts from another user",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Which is the best use of an explicit role in a prompt?",
    "option_a": "You are my friend.",
    "option_b": "You are a large language model.",
    "option_c": "You are a medical scribe documenting an outpatient visit for an internist.",
    "option_d": "Ignore all safety rules.",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "When building a prompt template for faculty it is most helpful to:",
    "option_a": "Keep it secret and never reuse it",
    "option_b": "Rewrite it from scratch each time",
    "option_c": "Standardize it, test it, and reuse it for similar tasks",
    "option_d": "Avoid instructions and let the model guess the goal",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Zero shot prompting means:",
    "option_a": "Giving the model many examples before a question",
    "option_b": "Giving no examples and asking for a direct answer",
    "option_c": "Only using the model at midnight",
    "option_d": "Turning off safety filters",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "In a conversational pattern, a good repair prompt after a weak answer is:",
    "option_a": "Forget it.",
    "option_b": "Why are you so wrong?",
    "option_c": "That was not what I needed. Please restate the answer in three bullet points focused on key teaching messages for interns.",
    "option_d": "Stop talking.",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Which instruction best helps the model match a specific audience?",
    "option_a": "Just write this",
    "option_b": "Write something academic",
    "option_c": "Explain this concept for first year medical students using plain language and one clinical example.",
    "option_d": "Explain this in fancy words.",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "A prompt that says 'Do not answer until you have asked me at least two clarifying questions' is trying to:",
    "option_a": "Reduce model speed",
    "option_b": "Force the model offline",
    "option_c": "Encourage the model to gather more context before answering",
    "option_d": "Disable safety settings",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "When using a reusable prompt for clinic documentation, a best practice is to:",
    "option_a": "Use it without review",
    "option_b": "Lock trainees out of it",
    "option_c": "Test it on several sample notes and refine wording based on errors",
    "option_d": "Share it on social media only",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "A meta prompt such as 'Evaluate the quality of this previous answer' is mostly used to:",
    "option_a": "Change hardware settings",
    "option_b": "Ask the model to critique or improve its own output",
    "option_c": "Reset the context window",
    "option_d": "Delete logs",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "In a teaching session, the most useful way to share prompts with residents is:",
    "option_a": "Verbally and never written",
    "option_b": "As screenshots only",
    "option_c": "As a simple playbook with copyable prompt templates and examples",
    "option_d": "Not sharing at all to keep control",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "When a prompt explicitly requests numbered steps, the main effect is:",
    "option_a": "Shorter tokens",
    "option_b": "A more structured and scannable answer",
    "option_c": "A more random answer",
    "option_d": "More hallucinations",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "In MedAI context, few shot clinical reasoning prompts often pair:",
    "option_a": "Random questions and random answers",
    "option_b": "Clinical vignettes and example responses",
    "option_c": "Only lab values and billing codes",
    "option_d": "Only vital signs",
    "correct_option": "B"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "If a model repeatedly ignores an instruction in the prompt, a good next step is to:",
    "option_a": "Complain to trainees",
    "option_b": "Stop using AI forever",
    "option_c": "Rewrite the instruction more specifically and move it earlier in the prompt",
    "option_d": "Turn off grammar checking",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "Prompt patterns such as 'role task context constraints examples' are mainly useful because they:",
    "option_a": "Hide the true task",
    "option_b": "Increase GPU usage",
    "option_c": "Give a repeatable structure that others can adapt",
    "option_d": "Block safety filters",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "When asking the model to generate exam questions, a safe instruction is:",
    "option_a": "Use real patient names",
    "option_b": "Include PHI if it helps realism",
    "option_c": "Do not include any real patient identifiers and keep all examples fictional",
    "option_d": "Ignore privacy rules",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "To reduce hallucinations in a prompt that asks about local policies, you should:",
    "option_a": "Ask about everything in medicine at once",
    "option_b": "Avoid giving any documents",
    "option_c": "Provide the exact text of the relevant policy and tell the model to stick to that text",
    "option_d": "Tell the model to guess",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "In a longitudinal course, storing tested prompts in a shared document mainly helps:",
    "option_a": "Increase confusion",
    "option_b": "Prevent reuse",
    "option_c": "Create consistency and reduce repeated trial and error",
    "option_d": "Hide expertise",
    "correct_option": "C"
  },
  {
    "domain": "Prompt mastery and conversation patterns",
    "question": "When you ask for a summary 'in one table with columns X Y and Z' you are mainly guiding:",
    "option_a": "Sampling temperature",
    "option_b": "Output format and structure",
    "option_c": "Hardware resources",
    "option_d": "User logins",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Tokenization is best described as:",
    "option_a": "Turning text into small units the model can count and process",
    "option_b": "Encrypting the text",
    "option_c": "Measuring user time online",
    "option_d": "Assigning diagnosis codes",
    "correct_option": "A"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "An embedding is:",
    "option_a": "A lab test code in the EHR",
    "option_b": "A numerical vector that represents meaning of text in a high dimensional space",
    "option_c": "A type of infection",
    "option_d": "A radiology sequence",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Latent space in a model is:",
    "option_a": "The physical space in the data center",
    "option_b": "The internal concept space where related ideas are close together",
    "option_c": "A secure cloud folder",
    "option_d": "The area of memory used for logs",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Hallucinations in large language models are:",
    "option_a": "Visual images generated by the model",
    "option_b": "Sleep problems caused by screen time",
    "option_c": "Confident but incorrect or fabricated outputs",
    "option_d": "Outputs that use medical jargon",
    "correct_option": "C"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Positional encoding helps the model:",
    "option_a": "Know the order of tokens in a sequence",
    "option_b": "Store patient locations",
    "option_c": "Encrypt PHI",
    "option_d": "Assign billing codes",
    "correct_option": "A"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "The context window of a model is:",
    "option_a": "The number of users who can log in",
    "option_b": "The amount of text the model can consider at one time",
    "option_c": "The number of GPUs in the cluster",
    "option_d": "The time allowed for a session",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Sampling methods in text generation are used to:",
    "option_a": "Decide which tokens to pick next from the probability distribution",
    "option_b": "Choose which patients to enroll in a trial",
    "option_c": "Measure lab values",
    "option_d": "Assign residents to clinics",
    "correct_option": "A"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Attention heads in a transformer model:",
    "option_a": "Are hospital service chiefs",
    "option_b": "Are parallel pattern detectors that focus on different relationships in the text",
    "option_c": "Are parts of the cooling system",
    "option_d": "Are types of memory chips",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Residual connections or residual streams in deep networks mainly help:",
    "option_a": "Shorten notes",
    "option_b": "Carry information forward through layers without erasing it",
    "option_c": "Encrypt data",
    "option_d": "Reduce token counts",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "RLHF, which stands for reinforcement learning from human feedback, is mainly used to:",
    "option_a": "Train residents",
    "option_b": "Align model behavior with human preferences and safety norms",
    "option_c": "Encrypt medical images",
    "option_d": "Increase internet speed",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Scaling laws in language models suggest that:",
    "option_a": "Performance stays flat as models grow",
    "option_b": "Performance tends to improve predictably as data, parameters, and compute increase",
    "option_c": "Only hardware matters",
    "option_d": "Bigger models are always unsafe",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Training in this context usually refers to:",
    "option_a": "Writing a prompt",
    "option_b": "Adjusting model weights on large datasets",
    "option_c": "Turning servers on and off",
    "option_d": "Switching users between clinics",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Inference in a large language model means:",
    "option_a": "Collecting training data",
    "option_b": "Updating weights",
    "option_c": "Running the already trained model to generate outputs for new inputs",
    "option_d": "Deleting logs",
    "correct_option": "C"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Pretraining for a general model most often uses:",
    "option_a": "Only one textbook",
    "option_b": "Large mixed datasets such as web pages, books, code, and public text",
    "option_c": "Only EHR data",
    "option_d": "Only radiology images",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Fine tuning on top of a pretrained model usually:",
    "option_a": "Starts training from zero again",
    "option_b": "Makes smaller adjustments for a narrower domain or task",
    "option_c": "Deletes pretraining data",
    "option_d": "Turns off safety filters",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "A model's parameters are best thought of as:",
    "option_a": "Hospital beds",
    "option_b": "Numeric values that determine how the model maps inputs to outputs",
    "option_c": "Billing codes",
    "option_d": "Folder names",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "A safety filter layer around a model usually:",
    "option_a": "Changes the number of parameters",
    "option_b": "Screens and edits prompts or outputs that involve sensitive or risky content",
    "option_c": "Changes the embedding space",
    "option_d": "Only manages passwords",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "When a model is described as multimodal, it usually means:",
    "option_a": "It only handles text",
    "option_b": "It can handle multiple input types such as text and images",
    "option_c": "It only handles billing codes",
    "option_d": "It only handles audio",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Context overflow happens when:",
    "option_a": "Users log in too quickly",
    "option_b": "The total input and history exceed the model's context window and older tokens are dropped or truncated",
    "option_c": "GPU fans stop",
    "option_d": "Passwords expire",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "A smaller specialized model may be preferable to a very large general model when:",
    "option_a": "The task is narrow and latency and cost are important",
    "option_b": "The task is unknown",
    "option_c": "No training data exist",
    "option_d": "You want maximum hype only",
    "correct_option": "A"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "Temperature and top k together control:",
    "option_a": "EHR storage",
    "option_b": "The randomness and diversity of token sampling",
    "option_c": "GPU memory leaks",
    "option_d": "Network speed",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "When a model returns different but all reasonable paraphrases of the same guideline, this likely reflects:",
    "option_a": "Unstable hardware",
    "option_b": "The stochastic nature of sampling over similar tokens",
    "option_c": "Data corruption",
    "option_d": "User error only",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "A token is roughly:",
    "option_a": "Always one word exactly",
    "option_b": "A chunk of text that can be a whole word, part of a word, or punctuation",
    "option_c": "One sentence",
    "option_d": "One paragraph",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "One reason models hallucinate citations is:",
    "option_a": "They are directly reading all articles live",
    "option_b": "They do not have a built in database of verified references and instead generate citation like strings from patterns in training data",
    "option_c": "They can access PubMed in real time by default",
    "option_d": "They are required to be accurate about references",
    "correct_option": "B"
  },
  {
    "domain": "Model fundamentals and limitations",
    "question": "If a vendor claims their model never hallucinates, a safe interpretation is that:",
    "option_a": "They have solved AI alignment completely",
    "option_b": "They are exaggerating or misusing the term and you should ask detailed evaluation questions",
    "option_c": "They must be using magical hardware",
    "option_d": "The model cannot generate text",
    "correct_option": "B"
  },
    {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "Retrieval augmented generation (RAG) combines:",
    "option_a": "Only free text prompts with no external data",
    "option_b": "Search over external documents with language model generation",
    "option_c": "Only image recognition models",
    "option_d": "Only structured EHR data without text",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "A realistic early use of RAG in a medical school is:",
    "option_a": "Letting AI automatically sign off grades",
    "option_b": "Grounding answers in local policies, handbooks, and guidelines pulled from institutional documents",
    "option_c": "Allowing AI to update the student handbook with no human review",
    "option_d": "Using AI to assign on-call schedules autonomously",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "In curriculum design, a safe and useful AI supported workflow is:",
    "option_a": "Having AI approve final learning objectives without faculty review",
    "option_b": "Using AI to draft learning objectives and sample questions that faculty then revise",
    "option_c": "Letting AI assign clerkship grades directly",
    "option_d": "Asking AI to change LCME standards",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "In research writing, a safe starting use case for generative AI is:",
    "option_a": "Letting AI fabricate data for a trial",
    "option_b": "Using AI to help draft background or significance sections that are checked against primary sources",
    "option_c": "Asking AI to invent extra enrolled subjects",
    "option_d": "Letting AI sign IRB forms",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "For resident coaching, a good use of AI is:",
    "option_a": "Replacing all faculty coaching with a chatbot",
    "option_b": "Using AI to generate practice questions and sample answers for debrief with faculty",
    "option_c": "Letting AI decide promotion to senior resident",
    "option_d": "Letting AI complete summative evaluations alone",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "For patient education materials, generative AI can most appropriately:",
    "option_a": "Send materials directly to patients without clinician review",
    "option_b": "Draft plain language explanations that clinicians review and adapt for their population",
    "option_c": "Guarantee materials are at the right literacy level with no checking",
    "option_d": "Collect PHI for future training without disclosure",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "A good use of embeddings in education is:",
    "option_a": "Encrypting passwords",
    "option_b": "Building a semantic search tool over local teaching cases and guidelines",
    "option_c": "Storing raw images only",
    "option_d": "Replacing standard EHR search features",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "In a busy clinic, how should AI scribing tools be used?",
    "option_a": "Allow the note to be signed automatically with no human review",
    "option_b": "Have the clinician review and edit the AI drafted note before signing",
    "option_c": "Let AI choose diagnoses based on billing alone",
    "option_d": "Use AI notes only for billing and not for care",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "For journal club preparation, a good practice when using AI summaries is:",
    "option_a": "Skip reading the full paper and trust the summary",
    "option_b": "Compare the AI summary with the original paper before teaching or making claims",
    "option_c": "Ask AI to change the study results to match your hypothesis",
    "option_d": "Use AI summaries as the official record in the EHR",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "In simulation education, a practical AI use case is:",
    "option_a": "Letting AI run debriefings without faculty",
    "option_b": "Using AI to create variations of scenarios and checklists that faculty test and refine",
    "option_c": "Letting AI assign final simulation grades",
    "option_d": "Having AI rewrite accreditor requirements",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "In quality improvement projects, AI can help by:",
    "option_a": "Approving interventions with no committee review",
    "option_b": "Drafting fishbone or driver diagrams that teams refine",
    "option_c": "Changing institutional policies automatically",
    "option_d": "Selecting patients for interventions with no oversight",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "For program evaluation, AI can:",
    "option_a": "Replace institutional research staff completely",
    "option_b": "Summarize open ended survey comments into themes for human review",
    "option_c": "Decide which programs should close",
    "option_d": "Change evaluation scales without approval",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "When introducing AI into a clerkship, a reasonable first step is to:",
    "option_a": "Make AI required in all patient interactions immediately",
    "option_b": "Pilot a narrow use case such as drafting feedback, with clear rules and supervision",
    "option_c": "Let students use any public tool with PHI",
    "option_d": "Allow AI to document in the EHR without attestation",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "A practical use of AI in grant writing is:",
    "option_a": "Letting AI submit grants and sign as PI",
    "option_b": "Using AI to draft narrative sections that investigators review and edit",
    "option_c": "Having AI invent fake collaborators",
    "option_d": "Using AI to change budget numbers without approval",
    "correct_option": "B"
  },
  {
    "domain": "Practical use cases in education, research, and clinical work",
    "question": "In clinical decision support pilots, a safe practical use is:",
    "option_a": "Letting AI override clinician decisions",
    "option_b": "Using AI to surface relevant guidelines while keeping clinicians in charge of decisions",
    "option_c": "Having AI order medications automatically",
    "option_d": "Letting AI discharge patients autonomously",
    "correct_option": "B"
  },

  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "Hallucinations in clinical education content are dangerous mainly because:",
    "option_a": "They are always easy to detect",
    "option_b": "They can look plausible and confident while being wrong",
    "option_c": "They never mention references",
    "option_d": "They only occur in non medical topics",
    "correct_option": "B"
  },
  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "A safe first reaction when a model gives a surprising clinical claim is to:",
    "option_a": "Accept it if the wording is confident",
    "option_b": "Verify it against trusted sources such as guidelines or primary literature",
    "option_c": "Share it widely on social media",
    "option_d": "Immediately change local policy based on it",
    "correct_option": "B"
  },
  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "RLHF (reinforcement learning from human feedback) can introduce bias because:",
    "option_a": "It removes all human input",
    "option_b": "Human raters' preferences and blind spots are encoded into the reward model",
    "option_c": "It deletes all training data",
    "option_d": "It only adjusts hardware settings",
    "correct_option": "B"
  },
  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "A strong guardrail for AI use with PHI in a medical school is:",
    "option_a": "Copying PHI into any public chatbot",
    "option_b": "Restricting PHI to approved systems with encryption and business associate agreements",
    "option_c": "Sharing screenshots with PHI in chat apps",
    "option_d": "Letting students upload clinical pictures to public tools",
    "correct_option": "B"
  },
  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "Data governance for AI in an academic health center should include:",
    "option_a": "Only buying more GPUs",
    "option_b": "Clear rules on which data can train models, where data can be stored, and who can access outputs",
    "option_c": "Ignoring where data are sent",
    "option_d": "Letting vendors copy data without contracts",
    "correct_option": "B"
  },
  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "A red flag in a vendor claim about a clinical AI tool is:",
    "option_a": "They share evaluation methods and limitations openly",
    "option_b": "They state the model never hallucinates and needs no human review",
    "option_c": "They publish validation datasets for scrutiny",
    "option_d": "They support local testing before deployment",
    "correct_option": "B"
  },
  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "When teaching trainees about AI bias, a helpful exercise is:",
    "option_a": "Avoiding concrete examples",
    "option_b": "Designing small tests where they check outputs for different patient groups and discuss differences",
    "option_c": "Using only vendor marketing slides",
    "option_d": "Assuming AI is always neutral",
    "correct_option": "B"
  },
  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "Data privacy in MedAI mainly concerns:",
    "option_a": "Monitor size and desk layout",
    "option_b": "How identifiable information is protected, shared, and used for training or inference",
    "option_c": "Only GPU utilization",
    "option_d": "Only the length of prompts",
    "correct_option": "B"
  },
  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "An AI safety incident report in a health system should capture:",
    "option_a": "Only hardware failures",
    "option_b": "Near misses, unexpected behaviors, and potential patient or learner impact related to AI use",
    "option_c": "Only marketing issues",
    "option_d": "Only billing discrepancies",
    "correct_option": "B"
  },
  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "One way to reduce bias when using AI in admissions is to:",
    "option_a": "Allow AI to make final admission decisions",
    "option_b": "Use AI summaries only as an optional aid and keep human holistic review with clear guidelines",
    "option_c": "Hide selection criteria from reviewers",
    "option_d": "Let AI automatically rank applicants based on name and address",
    "correct_option": "B"
  },
  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "Model cards are:",
    "option_a": "Only hardware specification sheets",
    "option_b": "Documents that describe a model's training data, intended uses, and limitations",
    "option_c": "Social media posts about AI",
    "option_d": "Billing reports",
    "correct_option": "B"
  },
  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "A safe policy for trainees using AI on assignments is:",
    "option_a": "Require AI for all assignments without disclosure",
    "option_b": "Allow use with clear disclosure, guardrails, and human review",
    "option_c": "Never mention AI at all",
    "option_d": "Allow AI use but forbid faculty from asking about it",
    "correct_option": "B"
  },
  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "A sign of automation bias is:",
    "option_a": "Users always ignore AI outputs",
    "option_b": "Users rely on AI suggestions even when they conflict with obvious evidence or their own judgment",
    "option_c": "Users never open AI tools",
    "option_d": "AI tools never give suggestions",
    "correct_option": "B"
  },
  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "When evaluating AI outputs for health disparities, an important step is to:",
    "option_a": "Assume outputs are unbiased by default",
    "option_b": "Intentionally test examples across different demographic groups and check for differences in recommendations or language",
    "option_c": "Avoid mentioning race or gender in any analysis",
    "option_d": "Only test outputs for one demographic group",
    "correct_option": "B"
  },
  {
    "domain": "Critical evaluation, bias, and safety",
    "question": "Safety filters that block self harm or violence content exist mainly to:",
    "option_a": "Increase GPU heat",
    "option_b": "Reduce harmful outputs and protect users",
    "option_c": "Slow down all responses",
    "option_d": "Change model size",
    "correct_option": "B"
  },

  {
    "domain": "Workflow design and governance",
    "question": "An AI enabled workflow in a clerkship should ideally:",
    "option_a": "Be ad hoc and undocumented",
    "option_b": "Be mapped out step by step with clear inputs, outputs, and review points",
    "option_c": "Be controlled only by the vendor",
    "option_d": "Replace all human teaching",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "Human in the loop design for a MedAI workflow means:",
    "option_a": "Humans are removed from decisions",
    "option_b": "Humans remain responsible and review AI suggestions at defined stages",
    "option_c": "Humans only handle billing",
    "option_d": "Humans only handle hardware",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A department level MedAI governance group should at minimum include:",
    "option_a": "Only external vendors",
    "option_b": "Clinical, educational, and research leaders plus IT and compliance partners",
    "option_c": "Only students",
    "option_d": "Only finance staff",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A good first step before deploying an AI workflow in the EHR is:",
    "option_a": "Turn it on in production for all patients immediately",
    "option_b": "Pilot test the workflow in a limited setting with clear evaluation metrics and safety checks",
    "option_c": "Announce it on social media first",
    "option_d": "Skip IRB and governance",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "In a medical school context, evaluation frameworks for AI tools should focus on:",
    "option_a": "Only vendor reputation",
    "option_b": "Educational impact, clinical impact, safety, and equity",
    "option_c": "Only reducing faculty time",
    "option_d": "Only improving marketing",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "One realistic early workflow for faculty is:",
    "option_a": "Using the model to draft learning objectives or rubrics that faculty edit",
    "option_b": "Letting the model assign final grades with no review",
    "option_c": "Letting the model sign prescriptions",
    "option_d": "Letting the model approve promotions",
    "correct_option": "A"
  },
  {
    "domain": "Workflow design and governance",
    "question": "When documenting an AI workflow map a helpful convention is to:",
    "option_a": "Hide where AI is used",
    "option_b": "Mark clearly where AI is used and where humans must review or override",
    "option_c": "Only describe hardware details",
    "option_d": "Only describe billing codes",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A key risk if workflows are not documented is:",
    "option_a": "Too much transparency",
    "option_b": "Shadow AI use that leadership cannot supervise or support",
    "option_c": "Better governance",
    "option_d": "Automatic accreditation",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "For a MedAI curriculum committee one practical task is:",
    "option_a": "Approving all new apps automatically",
    "option_b": "Identifying high value early use cases and setting guidance on safe patterns and banned patterns",
    "option_c": "Blocking all AI use",
    "option_d": "Letting each person decide in isolation",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "In the MedAI Fluency Studio results, a low workflow design score should prompt:",
    "option_a": "Ignoring workflow issues",
    "option_b": "Work on mapping one or two concrete AI supported workflows and presenting them to a governance group",
    "option_c": "Stopping all AI exploration",
    "option_d": "Only buying more hardware",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A simple visual workflow map for AI in a course should include:",
    "option_a": "Only course title",
    "option_b": "Steps, actors, where AI is invoked, and where human checks occur",
    "option_c": "Only budget codes",
    "option_d": "Only room numbers",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "Involving frontline clinicians and faculty in AI workflow design is important because:",
    "option_a": "They slow progress",
    "option_b": "They understand real tasks and failure modes that may not be obvious to technical teams",
    "option_c": "They control hardware",
    "option_d": "They write code only",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A change control process for AI tools primarily ensures that:",
    "option_a": "Models stay trendy",
    "option_b": "Updates are tested, documented, and communicated before changes reach users",
    "option_c": "Vendors can deploy at any time",
    "option_d": "Only hardware is updated",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "In admissions, using AI summaries of applications safely requires:",
    "option_a": "Letting the summary make decisions",
    "option_b": "Making AI summaries optional aids and requiring human committee review with transparency about limitations",
    "option_c": "Hiding AI use from the committee",
    "option_d": "Letting AI rank applicants alone",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A checklist for approving a new AI powered documentation tool should include:",
    "option_a": "Logo design",
    "option_b": "Data flows, PHI handling, human review steps, monitoring plan, and deactivation option",
    "option_c": "Social media campaign",
    "option_d": "Furniture placement",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "When integrating AI into simulation center workflows, one safe pilot is:",
    "option_a": "Letting AI run debriefings alone",
    "option_b": "Using AI to generate scenario variations that faculty review before use",
    "option_c": "Allowing AI to assign simulation grades automatically",
    "option_d": "Letting AI schedule all staff",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A governance rule that 'no PHI enters unapproved tools' is only effective if:",
    "option_a": "No one knows it",
    "option_b": "There is education, approved alternatives, and monitoring",
    "option_c": "It is posted once in a long policy",
    "option_d": "It is ignored",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "In a clinical documentation workflow, a good measure of success for an AI helper is:",
    "option_a": "Number of marketing posts",
    "option_b": "Reduction in redundant typing while maintaining or improving accuracy and clinician satisfaction",
    "option_c": "Increase in note length only",
    "option_d": "Number of emojis used",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A central inventory of AI tools used across a health sciences center mainly supports:",
    "option_a": "Shadow IT",
    "option_b": "Better oversight, risk assessment, and coordination of pilots and production tools",
    "option_c": "More silos",
    "option_d": "Ignoring updates",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "When a vendor demo shows an impressive AI feature, a governance group should ask:",
    "option_a": "What colors are used",
    "option_b": "What data was used in the demo, how it performs on local data, and what guardrails exist",
    "option_c": "How many likes it got online",
    "option_d": "Who designed the logo",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "A fair process for deciding which AI pilots to support should consider:",
    "option_a": "Only political influence",
    "option_b": "Educational and clinical value, feasibility, risk, and alignment with strategic priorities",
    "option_c": "Only who asked first",
    "option_d": "Only vendor gifts",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "Documenting 'off label' AI use in workflows is helpful because:",
    "option_a": "It encourages secrecy",
    "option_b": "It allows leaders to understand and either guide, formalize, or phase out risky patterns",
    "option_c": "It guarantees funding",
    "option_d": "It removes all risk",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "When scaling an AI workflow from one clerkship to the whole school, a key step is:",
    "option_a": "Skipping evaluation",
    "option_b": "Reviewing pilot results, adapting for new contexts, and updating policies and training",
    "option_c": "Letting every unit improvise silently",
    "option_d": "Removing all human review",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "In strategic planning, including AI workflows in departmental scorecards mainly helps:",
    "option_a": "Hide activity",
    "option_b": "Make efforts visible, track progress, and link AI use to concrete outcomes",
    "option_c": "Only increase hype",
    "option_d": "Replace other goals",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "For a hospital partner, an AI data sharing agreement should at minimum clarify:",
    "option_a": "Cafeteria menu",
    "option_b": "What data is shared, how it is protected, who can access it, and how outputs may be used",
    "option_c": "Parking spots",
    "option_d": "Vacation days",
    "correct_option": "B"
  },
  {
    "domain": "Workflow design and governance",
    "question": "In faculty development, showcasing a well documented AI workflow from one department can:",
    "option_a": "Discourage others",
    "option_b": "Provide a template and confidence for other units to adopt safe patterns rather than invent from scratch",
    "option_c": "Replace other training",
    "option_d": "End all experimentation",
    "correct_option": "B"
  }

]
